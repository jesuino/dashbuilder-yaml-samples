# HELP nv_inference_request_success Number of successful inference requests, all batch sizes
# TYPE nv_inference_request_success counter
nv_inference_request_success{model="inception_graphdef",version="1"} 0.000000
nv_inference_request_success{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_request_failure Number of failed inference requests, all batch sizes
# TYPE nv_inference_request_failure counter
nv_inference_request_failure{model="inception_graphdef",version="1"} 0.000000
nv_inference_request_failure{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_count Number of inferences performed (does not include cached requests)
# TYPE nv_inference_count counter
nv_inference_count{model="inception_graphdef",version="1"} 0.000000
nv_inference_count{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_exec_count Number of model executions performed (does not include cached requests)
# TYPE nv_inference_exec_count counter
nv_inference_exec_count{model="inception_graphdef",version="1"} 0.000000
nv_inference_exec_count{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_request_duration_us Cumulative inference request duration in microseconds (includes cached requests)
# TYPE nv_inference_request_duration_us counter
nv_inference_request_duration_us{model="inception_graphdef",version="1"} 0.000000
nv_inference_request_duration_us{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_queue_duration_us Cumulative inference queuing duration in microseconds (includes cached requests)
# TYPE nv_inference_queue_duration_us counter
nv_inference_queue_duration_us{model="inception_graphdef",version="1"} 0.000000
nv_inference_queue_duration_us{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_compute_input_duration_us Cumulative compute input duration in microseconds (does not include cached requests)
# TYPE nv_inference_compute_input_duration_us counter
nv_inference_compute_input_duration_us{model="inception_graphdef",version="1"} 0.000000
nv_inference_compute_input_duration_us{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_compute_infer_duration_us Cumulative compute inference duration in microseconds (does not include cached requests)
# TYPE nv_inference_compute_infer_duration_us counter
nv_inference_compute_infer_duration_us{model="inception_graphdef",version="1"} 0.000000
nv_inference_compute_infer_duration_us{model="densenet_onnx",version="1"} 0.000000
# HELP nv_inference_compute_output_duration_us Cumulative inference compute output duration in microseconds (does not include cached requests)
# TYPE nv_inference_compute_output_duration_us counter
nv_inference_compute_output_duration_us{model="inception_graphdef",version="1"} 0.000000
nv_inference_compute_output_duration_us{model="densenet_onnx",version="1"} 0.000000
# HELP nv_cache_num_entries Number of responses stored in response cache
# TYPE nv_cache_num_entries gauge
# HELP nv_cache_num_lookups Number of cache lookups in response cache
# TYPE nv_cache_num_lookups gauge
# HELP nv_cache_num_hits Number of cache hits in response cache
# TYPE nv_cache_num_hits gauge
# HELP nv_cache_num_misses Number of cache misses in response cache
# TYPE nv_cache_num_misses gauge
# HELP nv_cache_num_evictions Number of cache evictions in response cache
# TYPE nv_cache_num_evictions gauge
# HELP nv_cache_lookup_duration Total cache lookup duration (hit and miss), in microseconds
# TYPE nv_cache_lookup_duration gauge
# HELP nv_cache_insertion_duration Total cache insertion duration, in microseconds
# TYPE nv_cache_insertion_duration gauge
# HELP nv_cache_util Cache utilization [0.0 - 1.0]
# TYPE nv_cache_util gauge
# HELP nv_cache_num_hits_per_model Number of cache hits per model
# TYPE nv_cache_num_hits_per_model counter
nv_cache_num_hits_per_model{model="inception_graphdef",version="1"} 0.000000
nv_cache_num_hits_per_model{model="densenet_onnx",version="1"} 0.000000
# HELP nv_cache_hit_lookup_duration_per_model Total cache hit lookup duration per model, in microseconds
# TYPE nv_cache_hit_lookup_duration_per_model counter
nv_cache_hit_lookup_duration_per_model{model="inception_graphdef",version="1"} 0.000000
nv_cache_hit_lookup_duration_per_model{model="densenet_onnx",version="1"} 0.000000
# HELP nv_cache_num_misses_per_model Number of cache misses per model
# TYPE nv_cache_num_misses_per_model counter
nv_cache_num_misses_per_model{model="inception_graphdef",version="1"} 0.000000
nv_cache_num_misses_per_model{model="densenet_onnx",version="1"} 0.000000
# HELP nv_cache_miss_lookup_duration_per_model Total cache miss lookup duration per model, in microseconds
# TYPE nv_cache_miss_lookup_duration_per_model counter
nv_cache_miss_lookup_duration_per_model{model="inception_graphdef",version="1"} 0.000000
nv_cache_miss_lookup_duration_per_model{model="densenet_onnx",version="1"} 0.000000
# HELP nv_cache_miss_insertion_duration_per_model Total cache miss insertion duration per model, in microseconds
# TYPE nv_cache_miss_insertion_duration_per_model counter
nv_cache_miss_insertion_duration_per_model{model="inception_graphdef",version="1"} 0.000000
nv_cache_miss_insertion_duration_per_model{model="densenet_onnx",version="1"} 0.000000
# HELP nv_gpu_utilization GPU utilization rate [0.0 - 1.0)
# TYPE nv_gpu_utilization gauge
# HELP nv_gpu_memory_total_bytes GPU total memory, in bytes
# TYPE nv_gpu_memory_total_bytes gauge
# HELP nv_gpu_memory_used_bytes GPU used memory, in bytes
# TYPE nv_gpu_memory_used_bytes gauge
# HELP nv_gpu_power_usage GPU power usage in watts
# TYPE nv_gpu_power_usage gauge
# HELP nv_gpu_power_limit GPU power management limit in watts
# TYPE nv_gpu_power_limit gauge
# HELP nv_energy_consumption GPU energy consumption in joules since the Triton Server started
# TYPE nv_energy_consumption counter
